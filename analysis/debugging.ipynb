{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow to reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pmandica/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import SegformerForImageClassification, SegformerModel\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from core.datasets.build import transform\n",
    "from core.configs import cfg\n",
    "from core.models.segformer import *\n",
    "from core.utils.hyperbolic import HyperMapper, HyperMLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def parse_args(args_str: str = None):\n",
    "    parser = argparse.ArgumentParser(description=\"Active Domain Adaptive Semantic Segmentation Training\")\n",
    "    parser.add_argument(\"-cfg\",\n",
    "                        \"--config-file\",\n",
    "                        default=\"\",\n",
    "                        metavar=\"FILE\",\n",
    "                        help=\"path to config file\",\n",
    "                        type=str)\n",
    "    parser.add_argument(\"--proctitle\",\n",
    "                        type=str,\n",
    "                        default=\"HALO\",\n",
    "                        help=\"allow a process to change its title\", )\n",
    "    parser.add_argument(\n",
    "        \"opts\",\n",
    "        help=\"Modify config options using the command-line\",\n",
    "        default=None,\n",
    "        nargs=argparse.REMAINDER\n",
    "    )\n",
    "\n",
    "    args_list = args_str.split() if args_str else None\n",
    "    args = parser.parse_args(args_list)\n",
    "\n",
    "    if args.opts is not None and args.opts != []:\n",
    "        args.opts[-1] = args.opts[-1].strip('\\r\\n')\n",
    "\n",
    "    cfg.set_new_allowed(True)\n",
    "    cfg.merge_from_file(args.config_file)\n",
    "    cfg.merge_from_list(args.opts)\n",
    "    cfg.SAVE_DIR = os.path.join(cfg.OUTPUT_DIR, cfg.NAME)\n",
    "    print(\"Saving to {}\".format(cfg.SAVE_DIR))\n",
    "    cfg.freeze()\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to results/source_target/debug\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CfgNode({'MODEL': CfgNode({'NAME': 'deeplabv3plus_resnet101', 'NUM_CLASSES': 19, 'WEIGHTS': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth', 'FREEZE_BN': True, 'HYPER': True, 'CURVATURE': 1.0, 'REDUCED_CHANNELS': 64, 'HFR': True}), 'WANDB': CfgNode({'ENABLE': False, 'GROUP': 'source_target', 'PROJECT': 'active_domain_adapt', 'ENTITY': 'pinlab-sapienza'}), 'INPUT': CfgNode({'SOURCE_INPUT_SIZE_TRAIN': (1280, 720), 'TARGET_INPUT_SIZE_TRAIN': (1280, 640), 'INPUT_SIZE_TEST': (1280, 640), 'INPUT_SCALES_TRAIN': (1.0, 1.0), 'IGNORE_LABEL': 255, 'PIXEL_MEAN': [0.485, 0.456, 0.406], 'PIXEL_STD': [0.229, 0.224, 0.225], 'TO_BGR255': False}), 'DATASETS': CfgNode({'SOURCE_TRAIN': 'gtav_train', 'TARGET_TRAIN': 'cityscapes_train', 'TEST': 'cityscapes_val'}), 'SOLVER': CfgNode({'GPUS': [0], 'NUM_ITER': 60000, 'LR_METHOD': 'poly', 'BASE_LR': 0.001, 'LR_POWER': 0.5, 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0005, 'WARMUP_ITERS': 600, 'BATCH_SIZE': 2, 'BATCH_SIZE_VAL': 1, 'CONSISTENT_LOSS': 0.0, 'NEGATIVE_LOSS': 1.0, 'NEGATIVE_THRESHOLD': 0.05, 'LCR_TYPE': 'l1'}), 'ACTIVE': CfgNode({'NAME': 'HALO', 'UNCERTAINTY': 'entropy', 'PURITY': 'radius', 'SETTING': 'RA', 'SELECT_ITER': [0, 15000, 30000, 40000, 50000], 'BUDGET': 0.05, 'RADIUS_K': 1, 'NORMALIZE': True, 'MASK_RADIUS_K': 5, 'K': 100, 'VIZ_MASK': False, 'RATIO': 0.05}), 'TEST': CfgNode({'BATCH_SIZE': 1, 'VIZ_SCORE': False, 'VIZ_WRONG': False, 'SAVE_EMBED': False}), 'NAME': 'debug', 'OUTPUT_DIR': 'results/source_target/', 'resume': '', 'SEED': -1, 'DEBUG': 0, 'PROTOCOL': 'source_target', 'SAVE_DIR': 'results/source_target/debug'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = parse_args(\"-cfg ../configs/gtav/debug.yaml\")\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.datasets.build import build_dataset\n",
    "from core.datasets.cityscapes import cityscapesDataSet\n",
    "\n",
    "w, h = cfg.INPUT.TARGET_INPUT_SIZE_TRAIN\n",
    "trans_list = [\n",
    "    transform.ToTensor(),\n",
    "    transform.Normalize(mean=cfg.INPUT.PIXEL_MEAN, std=cfg.INPUT.PIXEL_STD, to_bgr255=cfg.INPUT.TO_BGR255)\n",
    "]\n",
    "if cfg.INPUT.INPUT_SCALES_TRAIN[0] == cfg.INPUT.INPUT_SCALES_TRAIN[1] and cfg.INPUT.INPUT_SCALES_TRAIN[0] == 1:\n",
    "    trans_list = [transform.Resize((h, w)), ] + trans_list\n",
    "else:\n",
    "    trans_list = [\n",
    "                        transform.RandomScale(scale=cfg.INPUT.INPUT_SCALES_TRAIN),\n",
    "                        transform.RandomCrop(size=(h, w), pad_if_needed=True),\n",
    "                    ] + trans_list\n",
    "trans = transform.Compose(trans_list)\n",
    "\n",
    "target_set = cityscapesDataSet(\n",
    "                \"../datasets/cityscapes\",\n",
    "                \"../datasets/cityscapes_train_list.txt\",\n",
    "                max_iters=1000,\n",
    "                num_classes=19,\n",
    "                split=\"train\",\n",
    "                transform=trans,\n",
    "                cfg=cfg,\n",
    "                empty=False,\n",
    "            )\n",
    "\n",
    "target_loader = DataLoader(\n",
    "            dataset=target_set,\n",
    "            batch_size=2,\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "            persistent_workers=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/pmandica/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/pmandica/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/pmandica/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/pmandica/HALO/analysis/../core/datasets/cityscapes.py\", line 234, in __getitem__\n    label_mask = np.array(Image.open(datafiles[\"label_mask\"]), dtype=np.uint8)\n  File \"/home/pmandica/miniconda3/envs/openmmlab/lib/python3.8/site-packages/PIL/Image.py\", line 3227, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: 'results/source_target/debug/gtMask/train/dusseldorf/dusseldorf_000157_000019_gtFine_labelIds.png'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/pmandica/HALO/analysis/debugging.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bbluefin/home/pmandica/HALO/analysis/debugging.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(target_loader))\n",
      "File \u001b[0;32m~/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1333\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1332\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1333\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   1358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1359\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1360\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/_utils.py:543\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    541\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/pmandica/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/pmandica/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/pmandica/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/pmandica/HALO/analysis/../core/datasets/cityscapes.py\", line 234, in __getitem__\n    label_mask = np.array(Image.open(datafiles[\"label_mask\"]), dtype=np.uint8)\n  File \"/home/pmandica/miniconda3/envs/openmmlab/lib/python3.8/site-packages/PIL/Image.py\", line 3227, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: 'results/source_target/debug/gtMask/train/dusseldorf/dusseldorf_000157_000019_gtFine_labelIds.png'\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(target_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 640, 1280])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = batch['img'], batch['label']\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(2, 3, 720, 1280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = SegformerModel.from_pretrained(\"nvidia/mit-b2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = feature_extractor.config\n",
    "config.num_labels = 19\n",
    "return_dict = config.use_return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = feature_extractor(img, output_hidden_states=True, return_dict=return_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_hidden_states = outputs.hidden_states if return_dict else outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = SegformerDecodeHead(config)\n",
    "head.post_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 90, 160])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = head(encoder_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 19, 160, 320])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "optimizer1 = Adam(feature_extractor.parameters(), lr=1e-4)\n",
    "optimizer2 = Adam(feature_extractor.parameters(), lr=1e-5)\n",
    "optims = [optimizer1, optimizer2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    lr: 1e-05\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "print(optims)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
